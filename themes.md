---
sidebar:
  - title: "Important Dates:"
    image_alt: "A human at the center of something, something, machine learning."
    text: "Papers Deadline: 12-Feb-2019"
  - extra: ""
    text: "Papers Decisions: 1-Mar-2019"
  - extra: ""
    text: "Workshop: 4-May-2019"

layout: single
title: Workshop Themes.
---

The concept of contestability in technology systems has deep roots in human-computer interaction. For example mixed-initiative systems were designed for users to compose final outcomes via negotiation with a system. And even the earliest experiments in expert systems revealed that experts must be able to "correct one or more of [the deductive steps and/or facts used] if necessary" [Buchanan 1984, Gorry 1973]. This history of designing for a "conversation" between a user and system has become ever more important as machine decisions have taken on greater and greater impact.

Recent work has called attention to the need for designing contestable decision making systems, but as with earlier expert systems work, this has focused on providing explanations to expert users. However, providing explanations and transparency into how decisions are made can be technically difficult. While researchers have explored how to address some of these issues, challenges remain. And even when explanations and transparency are possible, they may not be beneficial. One of the themes of the workshop is understanding how contestability offers value that differs from or can add to transparency and explanations. 

###Defining Contestability

Is contestability merely the ability to contest a decision? Or is it a deeper system property -- the ability to interrogate, investigate, scrutinize the system throughout the process of coming to a joint decision between human and algorithm? The former must surface information to the user; but the latter must also support interaction and co-construction of the final decision. 

In this workshop, we look to explore how these different conceptions of contestation and contestability have important impacts on system design. For example, a system that designs for contestation might assume that the user has little to no authority and can only contest a decision after the fact, whereas a system designed for contestability might assume the user has a real voice in the decision and allow that contestation during the decision making. The timing, expected interaction, and relative authority vary in these different processes in ways that matter. 

In part these factors have shaped why contestability in HCI has primarily focused on expert users rather than decision subjects. However, contestability can also be designed into end user systems. In the current design of airport security scanners, the system is set for each passenger to either male or female. The TSA or CBP agent decides the setting; if the machine identifies any anomalies relative to the selected gender, the passenger must be examined by an officer of the same gender. In the past, this has been a source of "horrifying experiences" for transgender and gender-nonconforming individuals. However, this is also a setting that could be a point of contestability for the public. TSA policies could instead allow individuals to, in real time, inform the constructs of the decision making. 

One of the major goals of this workshop is to explore how HCI and CSCW researchers can draw on experiences in other domains to understand the design of contestability as part of the algorithmic experience. Both from within computing (e.g., the history of expert systems) and in other domains (e.g., the law, education, insurance, etc.), how has contestability been defined and designed? What insights can be transferred, and what needs to be explored anew? And what would it mean to move from contesting decisions to achieving a deeper contestability?

###Foundations

One of the major goals of this workshop is to understand the ethical foundations of contestability and how it connects to (or provides tensions for) notions of fairness, accountability, and trustworthiness. While feeling one's voice has been heard addresses a fundamental need for perceptions of fairness, with particularly strong effects for marginalized or disempowered populations, current designs for contestability don't always achieve this result. Is this because they are designed for contestation instead of deeper notions of contestability? Or simply due to failures in the system design? In addition, when contestability within the decision making process results in inconsistent results across users, does that challenge notions of fairness overall? In this workshop, we hope to engage deeply from practical questions of implementing machine learning decision making systems to the ethical frameworks that underlie them. 

###Goals

In addition, this workshop seeks to explore the possible goals for contestability in algorithmic systems. In many existing systems, the target for contestation or appeals is changing an individual output. However, even these small goals may not succeed for users; recent work on content moderation systems has found that users experience the appeal process as ``speaking into a void". However, given the high impact of algorithmic decision making, interest has also grown in contesting decision making processes at scale, often in the form of auditing and detecting bias in these systems (for example, collectively auditing Twitter's content moderation around harassment). Thus, alternative goals for contesting algorithmic systems may be changing fundamental aspects of decision making processes or systematically increasing user trust. 

###Audiences

These examples of contesting decisions at scale draw in a related question: who are the audiences of contestability? How and why does contestability differ when the audience is experts, lay users or even regulators? Are there other audiences that should be taken into account? As mentioned, decisions about definitions about contestability signal important judgements about relative authority, but defining the audience and goals of contestability for various decision making systems also impact the timing and degree of interaction. That is, regulators might interact with a decision making systems at different times and in different ways than lay users, even though all designs aim for contestability.

###Moving Forward

In moving forward, this subfield must address both methods and outcomes for contestability. First, what is the best way to study contestability? Approaches have varied widely, from participant observation to large scale survey designs. Are there methods that are better or worse for eliciting understandings of contestability in designs? And secondly, what are the goals of this field of study? That is, with a better understanding of contestability in design, how can and should researchers and industry partners decide their aims? Are the goals to help individual users, combat large-scale structural bias, or both? This workshop hopes to set forth an agenda for important research in this area moving forward. 

